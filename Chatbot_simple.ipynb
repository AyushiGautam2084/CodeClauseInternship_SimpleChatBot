{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AyushiGautam2084/CodeClauseInternship_SimpleChatBot/blob/main/Chatbot_simple.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peKr0g17fUby",
        "outputId": "bee98341-e229-4acf-c8c3-2d360632dd60"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iSKObE4bfVhs",
        "outputId": "46ce79e1-8ebf-4fa5-b028-b2e52dc694ef"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.12.25)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.4)\n"
          ]
        }
      ],
      "source": [
        "pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0IUTeuslmA-",
        "outputId": "d2b5fe5b-fb27-49a6-835c-b9a270a68061"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.5/8.5 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m20.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.1.6)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit\n",
        "import sys\n",
        "!pip install pyngrok\n",
        "!pip install --upgrade pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo8LTG9Bffjs",
        "outputId": "3127de20-6b04-4f74-9c39-929aabd0b5e7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "import pyngrok\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.chat.util import Chat, reflections\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j36v5iaDgPPS"
      },
      "outputs": [],
      "source": [
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oO0Cp-2Zgbm2"
      },
      "outputs": [],
      "source": [
        "preprocessed_pairs =[]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SCNQiYFQBzkx",
        "outputId": "1090d925-6ccd-4e88-d9d1-276787385f8d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You: hi\n",
            "Bot: hello\n",
            "You: how are you\n",
            "Bot: I am good! What would you like to talk about\n",
            "You: what is your age\n",
            "Bot: quite young but a million times smarter than you\n",
            "You: exit\n",
            "Bot: Goodbye!\n"
          ]
        }
      ],
      "source": [
        "import string\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "class ChatbotModel:\n",
        "    def __init__(self):\n",
        "        self.preprocessed_pairs = []  # Initialize list to store preprocessed pairs\n",
        "\n",
        "        # Read data from file and preprocess\n",
        "        with open('/content/drive/MyDrive/chatbot dataset.txt', 'r', encoding='utf-8') as file:\n",
        "            for line in file:\n",
        "                user_input, chatbot_answer = line.strip().split('\\t')\n",
        "                user_input_tokens = word_tokenize(user_input.lower())\n",
        "                chatbot_answer_tokens = word_tokenize(chatbot_answer.lower())\n",
        "\n",
        "                # Preprocessing steps (remove punctuation, strip spaces)\n",
        "                user_input_tokens = [token for token in user_input_tokens if token not in string.punctuation]\n",
        "                chatbot_answer_tokens = [token for token in chatbot_answer_tokens if token not in string.punctuation]\n",
        "                user_input_tokens = [token.strip() for token in user_input_tokens if token.strip()]\n",
        "                chatbot_answer_tokens = [token.strip() for token in chatbot_answer_tokens if token.strip()]\n",
        "\n",
        "                # Add preprocessed pairs to list\n",
        "                if user_input_tokens and chatbot_answer_tokens:\n",
        "                    self.preprocessed_pairs.append((user_input_tokens, chatbot_answer_tokens))\n",
        "\n",
        "    def get_response(self, user_input):\n",
        "        # Preprocess user input\n",
        "        user_input_tokens = word_tokenize(user_input.lower())\n",
        "        user_input_tokens = [token for token in user_input_tokens if token not in string.punctuation]\n",
        "        user_input_tokens = [token.strip() for token in user_input_tokens if token.strip()]\n",
        "\n",
        "        # Check for specific sentences and provide predefined responses\n",
        "        if 'how' in user_input_tokens and 'are' in user_input_tokens and 'you' in user_input_tokens:\n",
        "            return \"I am good! What would you like to talk about\"\n",
        "\n",
        "        if 'that' in user_input_tokens and 's' in user_input_tokens and 'nice' in user_input_tokens:\n",
        "            return \"Thanks! How else can I assist you today?\"\n",
        "\n",
        "        # Find matching response based on user input\n",
        "        matched_responses = []\n",
        "        for input_tokens, response_tokens in self.preprocessed_pairs:\n",
        "            if all(word in user_input_tokens for word in input_tokens):\n",
        "                matched_responses.append(' '.join(response_tokens))\n",
        "\n",
        "        # If there are matching responses, randomly select one\n",
        "        if matched_responses:\n",
        "            return random.choice(matched_responses)\n",
        "\n",
        "        # If no matching responses, return a default message\n",
        "        return \"I'm sorry, I don't understand.\"\n",
        "\n",
        "# Example usage:\n",
        "chatbot = ChatbotModel()\n",
        "while True:\n",
        "    user_input = input(\"You: \")\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Bot: Goodbye!\")\n",
        "        break\n",
        "    response = chatbot.get_response(user_input)\n",
        "    print(\"Bot:\", response)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taub8kblw0uL",
        "outputId": "ecec65af-1c44-407c-f52a-2e3736c1a86a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing frontend.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile frontend.py\n",
        "import torch\n",
        "import time\n",
        "from torch.nn import functional as F\n",
        "import torch.nn as nn\n",
        "import streamlit as st\n",
        "import base64\n",
        "import string\n",
        "import random\n",
        "from nltk.tokenize import word_tokenize\n",
        "\n",
        "# Set the background image\n",
        "background_image = \"\"\"\n",
        "<style>\n",
        "[data-testid=\"stAppViewContainer\"] > .main {\n",
        "    background-image: url(\"https://images.unsplash.com/photo-1503455637927-730bce8583c0?q=80&w=2070&auto=format&fit=crop&ixlib=rb-4.0.3&ixid=M3wxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8fA%3D%3D\");\n",
        "    background-size: 100vw 100vh;  # This sets the size to cover 100% of the viewport width and height\n",
        "    background-position: center;\n",
        "    background-repeat: no-repeat;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "st.markdown(background_image, unsafe_allow_html=True)\n",
        "\n",
        "input_style = \"\"\"\n",
        "<style>\n",
        "input[type=\"text\"] {\n",
        "    background-color: transparent;\n",
        "    color: #a19eae;  // This changes the text color inside the input box\n",
        "}\n",
        "div[data-baseweb=\"base-input\"] {\n",
        "    background-color: transparent !important;\n",
        "}\n",
        "[data-testid=\"stAppViewContainer\"] {\n",
        "    background-color: transparent !important;\n",
        "}\n",
        "</style>\n",
        "\"\"\"\n",
        "\n",
        "class ChatbotModel:\n",
        "    def __init__(self):\n",
        "        self.preprocessed_pairs = []  # Initialize list to store preprocessed pairs\n",
        "        # Read data from file and preprocess\n",
        "        with open('/content/drive/MyDrive/chatbot dataset.txt', 'r', encoding='utf-8') as file:\n",
        "            for line in file:\n",
        "                user_input, chatbot_answer = line.strip().split('\\t')\n",
        "                user_input_tokens = word_tokenize(user_input.lower())\n",
        "                chatbot_answer_tokens = word_tokenize(chatbot_answer.lower())\n",
        "\n",
        "                # Preprocessing steps (remove punctuation, strip spaces)\n",
        "                user_input_tokens = [token for token in user_input_tokens if token not in string.punctuation]\n",
        "                chatbot_answer_tokens = [token for token in chatbot_answer_tokens if token not in string.punctuation]\n",
        "                user_input_tokens = [token.strip() for token in user_input_tokens if token.strip()]\n",
        "                chatbot_answer_tokens = [token.strip() for token in chatbot_answer_tokens if token.strip()]\n",
        "\n",
        "                # Add preprocessed pairs to list\n",
        "                if user_input_tokens and chatbot_answer_tokens:\n",
        "                    self.preprocessed_pairs.append((user_input_tokens, chatbot_answer_tokens))\n",
        "\n",
        "    def get_response(self, user_input):\n",
        "        # Preprocess user input\n",
        "        user_input_tokens = word_tokenize(user_input.lower())\n",
        "        user_input_tokens = [token for token in user_input_tokens if token not in string.punctuation]\n",
        "        user_input_tokens = [token.strip() for token in user_input_tokens if token.strip()]\n",
        "\n",
        "        # Check for specific sentences and provide predefined responses\n",
        "        if 'how' in user_input_tokens and 'are' in user_input_tokens and 'you' in user_input_tokens:\n",
        "            return \"I am good! What would you like to talk about\"\n",
        "\n",
        "        if 'thats' in user_input_tokens and 'nice' in user_input_tokens:\n",
        "            return \"Thanks! How else can I assist you today?\"\n",
        "\n",
        "        # Find matching response based on user input\n",
        "        matched_responses = []\n",
        "        for input_tokens, response_tokens in self.preprocessed_pairs:\n",
        "            if all(word in user_input_tokens for word in input_tokens):\n",
        "                matched_responses.append(' '.join(response_tokens))\n",
        "\n",
        "        # If there are matching responses, randomly select one\n",
        "        if matched_responses:\n",
        "            return random.choice(matched_responses)\n",
        "\n",
        "        # If no matching responses, return a default message\n",
        "        return \"I'm sorry, I don't understand.\"\n",
        "\n",
        "def main():\n",
        "    st.title('Simple ChatBot')\n",
        "    st.markdown('''Chat with the bot Cody''' )\n",
        "    user_input = st.text_input('You:', '')\n",
        "    if st.button('Send'):\n",
        "        chatbot = ChatbotModel()\n",
        "        response = chatbot.get_response(user_input)\n",
        "        st.text_area('Cody:', value=response, height=100)\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9NDQRlTy4rwy",
        "outputId": "2c9d982b-bb91-44ae-fe63-c94310eb1e44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[34;40mnotice\u001b[0m\u001b[35m\u001b[0m created a lockfile as package-lock.json. You should commit this file.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 2.021s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found 1 \u001b[93mmoderate\u001b[0m severity vulnerability\n",
            "  run `npm audit fix` to fix them, or `npm audit` for details\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!npm install localtunnel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mGAOopzq6nbo",
        "outputId": "90600dbf-ee8c-48a0-a963-e92e3bb6f3cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.225.204.244"
          ]
        }
      ],
      "source": [
        "!wget -q -O - https://loca.lt/mytunnelpassword"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aG3MqN27tifl"
      },
      "outputs": [],
      "source": [
        "!streamlit run /content/frontend.py &>/content/logs.txt&"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jmAcUyYw47zn",
        "outputId": "4c355adf-a1e3-4faa-ae74-c034332d84f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 2.012s\n",
            "your url is: https://busy-planets-cross.loca.lt\n",
            "^C\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nc8gcp_nRh8u",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        },
        "outputId": "58083098-ecf6-4bd2-ebdc-041de97ae486"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'import os\\nfrom threading import Thread\\nimport pyngrok\\n\\n# Check module import\\nif not hasattr(pyngrok, \\'conf\\'):\\n    raise ImportError(\"pyngrok.conf module not found. Please ensure you have imported the pyngrok library correctly.\")\\n\\n# Upgrade pyngrok library\\n!pip install --upgrade pyngrok\\n\\n# Check for conflicting names\\nconflicting_names = [name for name in globals() if name == \\'pyngrok.conf\\']\\nif conflicting_names:\\n    raise NameError(f\"Conflicting name detected: {conflicting_names[0]}. Please rename the variable or function to avoid conflicts.\")\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "'''import os\n",
        "from threading import Thread\n",
        "import pyngrok\n",
        "\n",
        "# Check module import\n",
        "if not hasattr(pyngrok, 'conf'):\n",
        "    raise ImportError(\"pyngrok.conf module not found. Please ensure you have imported the pyngrok library correctly.\")\n",
        "\n",
        "# Upgrade pyngrok library\n",
        "!pip install --upgrade pyngrok\n",
        "\n",
        "# Check for conflicting names\n",
        "conflicting_names = [name for name in globals() if name == 'pyngrok.conf']\n",
        "if conflicting_names:\n",
        "    raise NameError(f\"Conflicting name detected: {conflicting_names[0]}. Please rename the variable or function to avoid conflicts.\")\n",
        "'''\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z6oH1nuYECyM"
      },
      "outputs": [],
      "source": [
        "!pkill ngrok"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUp7qnoiSSu83cAW1UAjNn",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}